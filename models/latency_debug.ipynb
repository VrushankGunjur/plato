{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import whisper\n",
    "import openai\n",
    "import pinecone\n",
    "import random\n",
    "import string\n",
    "from revChatGPT.V1 import Chatbot\n",
    "\n",
    "indx = None\n",
    "chatbot = None\n",
    "index_again = True\n",
    "\n",
    "def chatgpt(res, query):\n",
    "    results = []\n",
    "    for result in res.matches:\n",
    "        # print(result.metadata.keys())\n",
    "        results.append(result.metadata['text'])\n",
    "\n",
    "    proc = results\n",
    "    s = \"\"\n",
    "    seen = set()\n",
    "    i = 0\n",
    "    count = 0\n",
    "    while i < len(proc):\n",
    "        indx1 = proc[i][0].find(';')\n",
    "        num = proc[i][0][:indx1]\n",
    "        proc[i][0] = proc[i][0][indx1+1:]\n",
    "        indx2 = proc[i][0].find(';')\n",
    "        title = proc[i][0][:indx2]\n",
    "        if title[:10] not in seen:\n",
    "            s += str(count+1) + \". \"\n",
    "            seen.add(title[:10])\n",
    "            indx3 = proc[i][0].find('Offered:')\n",
    "            info = proc[i][0][indx3:]\n",
    "            num = num[:len(num)-1]\n",
    "            s += (num + \", \" + title + \", \" + info)\n",
    "            s += \"\\n\"\n",
    "            count += 1\n",
    "        i += 1\n",
    "\n",
    "    p = \"Your name is Plato and you are a pair programmer for a developer. You are assisting them with what they're struggling with. Be specific in regard to helping with code and technical assistance. Here are some samples of code that may be relevant. Only use these to help if they make sense in context of the developer's thoughts: \\n\" + \\\n",
    "        s + \"\\n Talk to the developer directly. Please limit your response to less than 50 words. Respond to the following stream of thoughts from the developer: \"\n",
    "    prompt = p + query\n",
    "\n",
    "    prev_text = \"\"\n",
    "\n",
    "    for data in chatbot.ask(\n",
    "        prompt,\n",
    "    ):\n",
    "        message = data[\"message\"][len(prev_text) :]\n",
    "        # print(message, end=\"\", flush=True)\n",
    "        prev_text = data[\"message\"]\n",
    "        yield message\n",
    "\n",
    "    return prev_text\n",
    "\n",
    "def query_pinecone(p_indx, audio):\n",
    "    MODEL = \"text-embedding-ada-002\"\n",
    "    pinecone.init(\n",
    "        api_key=\"8dae86ff-8f12-4f00-900d-564cef7d98cb\",\n",
    "        environment=\"us-east1-gcp\"\n",
    "    )\n",
    "    indx = p_indx\n",
    "    query = audio\n",
    "    openai.api_key = \"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\"\n",
    "    xq = openai.Embedding.create(input=query, engine=MODEL)[\n",
    "        'data'][0]['embedding']\n",
    "    res = indx.query([xq], top_k=10, include_metadata=True)\n",
    "    return res\n",
    "    \n",
    "def chatbot_init():\n",
    "    global chatbot\n",
    "    chatbot = Chatbot(config={\n",
    "        \"email\": \"akshgarg@gmail.com\",\n",
    "        \"password\": \"treehacks\"\n",
    "    })\n",
    "\n",
    "def pinecone_init():\n",
    "    MODEL = \"text-embedding-ada-002\"\n",
    "\n",
    "    pinecone.init(\n",
    "        api_key=\"8dae86ff-8f12-4f00-900d-564cef7d98cb\",\n",
    "        environment=\"us-east1-gcp\"\n",
    "    )\n",
    "    \n",
    "    UID = 'plato'\n",
    "\n",
    "    if UID not in pinecone.list_indexes():\n",
    "        res = openai.Embedding.create(input='string.py', engine=MODEL)['data'][0]['embedding']\n",
    "        pinecone.create_index(UID, dimension=len(res))\n",
    "        # connect to index\n",
    "    \n",
    "    global indx\n",
    "    indx = pinecone.Index(UID)\n",
    "\n",
    "def index():\n",
    "    path = \"/Users/akshgarg/Downloads/plato/backend/codebase_files\"\n",
    "    dir_list = os.listdir(path)\n",
    "    print(dir_list)\n",
    "    openai.api_key = \"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\"\n",
    "    MODEL = \"text-embedding-ada-002\"\n",
    "    length = 15\n",
    "\n",
    "    CONST_SPLIT = 50 # should scale on average size or file type\n",
    "    chunk_i = 0\n",
    "    for f in dir_list:\n",
    "        if f == 'serve_files.py':\n",
    "            continue\n",
    "        pthname = path + '/' + f\n",
    "        if os.path.isdir(pthname):\n",
    "            continue\n",
    "        i = 0\n",
    "        with open(pthname, 'r') as file:\n",
    "        # iterate over each line in the file\n",
    "            chunk = ''\n",
    "            for line in file:\n",
    "                chunk += line\n",
    "                i += 1\n",
    "                if i == CONST_SPLIT:\n",
    "                    line = [chunk]\n",
    "                    id = [str(chunk_i)]\n",
    "                    res = openai.Embedding.create(input=line[0], engine=MODEL)\n",
    "                    embed = [(res['data'])[0]['embedding']]\n",
    "                    # prep metadata and upsert batch\n",
    "                    meta = [{'text': line}]\n",
    "                    to_upsert = zip(id, embed, meta)\n",
    "                    # upsert to Pinecone\n",
    "                    print(\"Inserted chunk \", chunk_i)\n",
    "                    indx.upsert(vectors=list(to_upsert))\n",
    "                    chunk_i += 1\n",
    "                    i = 0  # restart chunk\n",
    "                    chunk = ''\n",
    "            # extra text\n",
    "            if len(chunk) > 0:\n",
    "                line = [chunk]\n",
    "                id = [str(chunk_i)]\n",
    "                res = openai.Embedding.create(input=line[0], engine=MODEL)\n",
    "                embed = [(res['data'])[0]['embedding']]\n",
    "                # prep metadata and upsert batch\n",
    "                meta = [{'text': line}]\n",
    "                to_upsert = zip(id, embed, meta)\n",
    "                # upsert to Pinecone\n",
    "                print(\"Inserted chunk \", chunk_i)\n",
    "                indx.upsert(vectors=list(to_upsert))\n",
    "                chunk_i += 1\n",
    "                i = 0  # restart chunk\n",
    "                chunk = ''\n",
    "    return indx\n",
    "        \n",
    "def transcribe_sim(audio):\n",
    "    if len(audio) > 1:\n",
    "        global indx\n",
    "        if indx is None:\n",
    "            pinecone_init()\n",
    "\n",
    "        global chatbot\n",
    "        if chatbot is None:\n",
    "            chatbot_init()\n",
    "        \n",
    "        global index_again\n",
    "        if index_again:\n",
    "            indx = index()\n",
    "            index_again = False\n",
    "\n",
    "        res = query_pinecone(indx, audio)\n",
    "        final_msg = \"\"\n",
    "        for text in chatgpt(res, audio):\n",
    "            final_msg += text\n",
    "            print(text, end=\"\", flush = True)\n",
    "        \n",
    "        return final_msg\n",
    "    else:\n",
    "        res = 'No discernable audio captured.'\n",
    "        return res\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['whisper_standalone.py', 'whisper_async.py', 'app.py']\n",
      "Inserted chunk  0\n",
      "Inserted chunk  1\n",
      "Inserted chunk  2\n",
      "Inserted chunk  3\n",
      "Inserted chunk  4\n",
      "Inserted chunk  5\n",
      "Inserted chunk  6\n",
      "Inserted chunk  7\n",
      "For the first code sample, it seems to be a Python script for transcribing audio input using Google's Speech-to-Text API. Here are some suggestions to help the developer with their code:\n",
      "\n",
      "1. Since the script requires multiple imports, make sure that the necessary libraries are already installed. For example, the PyAudio library needs to be installed to record audio from a microphone, while the SpeechRecognition library can convert speech to text.\n",
      "2. It's a good practice to validate user inputs to avoid runtime errors. Make sure that the user provides valid arguments for each parameter, especially since some of them expect boolean, integer or float values.\n",
      "3. Check that the `whisper` library is already installed since it's used to load the trained model for transcribing audio. If it's not installed, you can use the `pip` package manager to install it using the command `!pip install whisper`.\n",
      "4. The `tempfile` library is used to create a temporary directory where the audio file is saved before being transcribed. Make sure to remove the directory and file after the transcription to prevent storage leaks.\n",
      "5. Since the audio file is recorded in a temporary directory, it's a good practice to create a context manager to handle the creation and deletion of the directory and file. You can use the `with` statement to ensure that the resources are released properly.\n",
      "6. The `check_stop_word` function checks if the predicted text is equal to the stop word. However, this function is only used to abort the transcription, and it's not used in the script. If it's not needed, you can remove it to simplify the code.\n",
      "7. To display verbose output, set the `verbose` argument to `True`. This will print additional information about the transcription process.\n",
      "\n",
      "Here's an updated version of the script with the suggested changes:\n",
      "\n",
      "```\n",
      "import argparse\n",
      "import io\n",
      "import os\n",
      "import tempfile\n",
      "from time import perf_counter\n",
      "\n",
      "import pyaudio\n",
      "import speech_recognition as sr\n",
      "import whisper\n",
      "\n",
      "parser = argparse.ArgumentParser(\n",
      "    formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
      "parser.add_argument(\"--model\", default=\"base\", help=\"Model to use\",\n",
      "                    choices=[\"tiny\", \"base\", \"small\", \"medium\", \"large\"])\n",
      "parser.add_argument(\"--english\", default=True,\n",
      "                    help=\"Whether to use English model\", type=bool)\n",
      "parser.add_argument(\"--stop_word\", default=\"stop\",\n",
      "                    help=\"Stop word to abort transcription\", type=str)\n",
      "parser.add_argument(\"--verbose\", default=False,\n",
      "                    help=\"Whether to print verbose output\", type=bool)\n",
      "parser.add_argument(\"--energy\", default=500,\n",
      "                    help=\"Energy level for mic to detect\", type=int)\n",
      "parser.add_argument(\"--dynamic_energy\", default=False,\n",
      "                    help=\"Flag to enable dynamic energy\", type=bool)\n",
      "parser.add_argument(\"--pause\", default=0.8,\n",
      "                    help=\"Minimum length of silence (sec) that will register as the end of a phrase\", type=float)\n",
      "args = parser.parse_args()\n",
      "\n",
      "\n",
      "def check_stop_word(predicted_text: str) -> bool:\n",
      "    return predicted_text.strip().lower() == args.stop_word\n",
      "\n",
      "\n",
      "def transcribe():\n",
      "    model = args.model\n",
      "    # there are no english models for large\n",
      "    if args.model != \"large\" and args.english:\n",
      "        model = model + \".en\"\n",
      "    audio_model = whisper.load_model(model)\n",
      "\n",
      "    # load the speech recognizer with CLI settings\n",
      "    r = sr.Recognizer()\n",
      "    r.energy_threshold = args.energy\n",
      "    r.pause_threshold = args.pause\n",
      "    r.dynamic_energy_threshold = args.dynamic_energy\n",
      "\n",
      "    with sr.Microphone(sample_rate=16000) as source:\n",
      "        print(\"Recording...\")\n",
      "        audio = r.listen(source)\n",
      "\n",
      "    # write audio to a WAV file\n",
      "    with tempfile.T"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'For the first code sample, it seems to be a Python script for transcribing audio input using Google\\'s Speech-to-Text API. Here are some suggestions to help the developer with their code:\\n\\n1. Since the script requires multiple imports, make sure that the necessary libraries are already installed. For example, the PyAudio library needs to be installed to record audio from a microphone, while the SpeechRecognition library can convert speech to text.\\n2. It\\'s a good practice to validate user inputs to avoid runtime errors. Make sure that the user provides valid arguments for each parameter, especially since some of them expect boolean, integer or float values.\\n3. Check that the `whisper` library is already installed since it\\'s used to load the trained model for transcribing audio. If it\\'s not installed, you can use the `pip` package manager to install it using the command `!pip install whisper`.\\n4. The `tempfile` library is used to create a temporary directory where the audio file is saved before being transcribed. Make sure to remove the directory and file after the transcription to prevent storage leaks.\\n5. Since the audio file is recorded in a temporary directory, it\\'s a good practice to create a context manager to handle the creation and deletion of the directory and file. You can use the `with` statement to ensure that the resources are released properly.\\n6. The `check_stop_word` function checks if the predicted text is equal to the stop word. However, this function is only used to abort the transcription, and it\\'s not used in the script. If it\\'s not needed, you can remove it to simplify the code.\\n7. To display verbose output, set the `verbose` argument to `True`. This will print additional information about the transcription process.\\n\\nHere\\'s an updated version of the script with the suggested changes:\\n\\n```\\nimport argparse\\nimport io\\nimport os\\nimport tempfile\\nfrom time import perf_counter\\n\\nimport pyaudio\\nimport speech_recognition as sr\\nimport whisper\\n\\nparser = argparse.ArgumentParser(\\n    formatter_class=argparse.ArgumentDefaultsHelpFormatter)\\nparser.add_argument(\"--model\", default=\"base\", help=\"Model to use\",\\n                    choices=[\"tiny\", \"base\", \"small\", \"medium\", \"large\"])\\nparser.add_argument(\"--english\", default=True,\\n                    help=\"Whether to use English model\", type=bool)\\nparser.add_argument(\"--stop_word\", default=\"stop\",\\n                    help=\"Stop word to abort transcription\", type=str)\\nparser.add_argument(\"--verbose\", default=False,\\n                    help=\"Whether to print verbose output\", type=bool)\\nparser.add_argument(\"--energy\", default=500,\\n                    help=\"Energy level for mic to detect\", type=int)\\nparser.add_argument(\"--dynamic_energy\", default=False,\\n                    help=\"Flag to enable dynamic energy\", type=bool)\\nparser.add_argument(\"--pause\", default=0.8,\\n                    help=\"Minimum length of silence (sec) that will register as the end of a phrase\", type=float)\\nargs = parser.parse_args()\\n\\n\\ndef check_stop_word(predicted_text: str) -> bool:\\n    return predicted_text.strip().lower() == args.stop_word\\n\\n\\ndef transcribe():\\n    model = args.model\\n    # there are no english models for large\\n    if args.model != \"large\" and args.english:\\n        model = model + \".en\"\\n    audio_model = whisper.load_model(model)\\n\\n    # load the speech recognizer with CLI settings\\n    r = sr.Recognizer()\\n    r.energy_threshold = args.energy\\n    r.pause_threshold = args.pause\\n    r.dynamic_energy_threshold = args.dynamic_energy\\n\\n    with sr.Microphone(sample_rate=16000) as source:\\n        print(\"Recording...\")\\n        audio = r.listen(source)\\n\\n    # write audio to a WAV file\\n    with tempfile.T'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcribe_sim(\"What is whisper doing?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone_init()\n",
    "chatbot_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['whisper_standalone.py', 'whisper_async.py', 'app.py']\n",
      "Inserted chunk  0\n",
      "Inserted chunk  1\n",
      "Inserted chunk  2\n",
      "Inserted chunk  3\n",
      "Inserted chunk  4\n",
      "Inserted chunk  5\n",
      "Inserted chunk  6\n",
      "Inserted chunk  7\n"
     ]
    }
   ],
   "source": [
    "indx = index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, happy to help! Let's take a look at each code sample and see what the developer may be struggling with.\n",
      "\n",
      "1. `shra`, `shray`\n",
      "\n",
      "Unfortunately, there isn't much information to go on with this one. Without knowing the context or seeing the surrounding code, it's hard to say what the issue might be. Can you provide more information?\n",
      "\n",
      "2. `vrushan`, `vrushank`\n",
      "\n",
      "Similarly, without more information, it's hard to say what the issue might be with this code. Is there anything else you can tell me about what the developer is struggling with?\n",
      "\n",
      "3. `aks`, `aksh`\n",
      "\n",
      "Again, I'm not sure what the problem is without more information. Is the developer encountering an error with this code?\n",
      "\n",
      "4. `si`, `sid`\n",
      "\n",
      "I'm sorry, but without context or more information, it's difficult to say what the problem might be with this code.\n",
      "\n",
      "5. This code is a Flask endpoint for a chatbot that uses OpenAI's GPT to generate responses to user queries. It appears that the `chatgpt` function takes in a request object that contains a user's query, and returns a response generated by the GPT model.\n",
      "\n",
      "If the developer is having issues with this code, some things to look out for might include ensuring that all necessary libraries are installed, that the Flask server is running correctly, and that the GPT model is properly configured and connected to the endpoint. Depending on the issue, debugging might involve inspecting error messages, checking the server logs, or walking through the code step-by-step to identify any bugs.\n",
      "\n",
      "6. This code is a Flask endpoint for handling file uploads. It checks that a file was uploaded with the request, saves each file to a specified folder, and returns a response indicating success.\n",
      "\n",
      "If the developer is struggling with this code, it's possible that there is an issue with the way files are being processed, or with the server not correctly receiving or handling requests. Debugging might involve checking that all necessary libraries are installed, confirming that the server is running, and walking through the code step-by-step to identify any bugs.\n",
      "\n",
      "7. This code appears to be a speech-to-text transcription script that uses an audio model to transcribe an input audio stream. It records the stream to a WAV file, processes the file using the audio model, and prints the resulting text to the console.\n",
      "\n",
      "If the developer is struggling with this code, some things to look out for might include ensuring that all necessary libraries are installed, checking that the audio model is configured and trained correctly, and that the speech-to-text processing is functioning as expected. Debugging might involve checking for error messages or exceptions, inspecting the console output, or walking through the code step-by-step to identify any bugs.\n",
      "\n",
      "8. This code appears to be a text chunking script that breaks up long strings of text into smaller, more manageable chunks. It takes in a string and a chunk size, and returns a list of chunks.\n",
      "\n",
      "If the developer is struggling with this code, it's possible that there is an issue with the way that the chunks are being created, or with the handling of edge cases where the text length is not evenly divisible by the chunk size. Debugging might involve walking through the code step-by-step, checking the output for correctness, and handling any exceptions or error messages that arise."
     ]
    }
   ],
   "source": [
    "audio = input(\"Enter audio: \")\n",
    "while audio != 'Done':\n",
    "    res = query_pinecone(indx, audio)\n",
    "    for text in chatgpt(res, audio):\n",
    "        print(text, end=\"\", flush = True)\n",
    "    audio = input(\"Enter audio: \")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = \"I'm currently stuck on identifying what files are actually important. I've never done flask before. This is stressful\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi, I'm Plato, and I'll be happy to assist you with your coding issues. Could you please provide more information about the problem you are facing? I noticed you have provided some code snippets. Could you provide some context around them and explain how I can help?"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AsAs aAs a As a pairAs a pair programmerAs a pair programmer,As a pair programmer, IAs a pair programmer, I'mAs a pair programmer, I'm happyAs a pair programmer, I'm happy toAs a pair programmer, I'm happy to As a pair programmer, I'm happy to helpAs a pair programmer, I'm happy to help youAs a pair programmer, I'm happy to help you.As a pair programmer, I'm happy to help you. HoweverAs a pair programmer, I'm happy to help you. However,As a pair programmer, I'm happy to help you. However, IAs a pair programmer, I'm happy to help you. However, I needAs a pair programmer, I'm happy to help you. However, I need moreAs a pair programmer, I'm happy to help you. However, I need more informationAs a pair programmer, I'm happy to help you. However, I need more information aboutAs a pair programmer, I'm happy to help you. However, I need more information about theAs a pair programmer, I'm happy to help you. However, I need more information about the problemsAs a pair programmer, I'm happy to help you. However, I need more information about the problems thatAs a pair programmer, I'm happy to help you. However, I need more information about the problems that theAs a pair programmer, I'm happy to help you. However, I need more information about the problems that the developerAs a pair programmer, I'm happy to help you. However, I need more information about the problems that the developer isAs a pair programmer, I'm happy to help you. However, I need more information about the problems that the developer is strugglingAs a pair programmer, I'm happy to help you. However, I need more information about the problems that the developer is struggling withAs a pair programmer, I'm happy to help you. However, I need more information about the problems that the developer is struggling with.As a pair programmer, I'm happy to help you. However, I need more information about the problems that the developer is struggling with. TheAs a pair programmer, I'm happy to help you. However, I need more information about the problems that the developer is struggling with. The codeAs a pair programmer, I'm happy to help you. However, I need more information about the problems that the developer is struggling with. The code snippetsAs a pair programmer, I'm happy to help you. However, I need more information about the problems that the developer is struggling with. The code snippets youAs a pair programmer, I'm happy to help you. However, I need more information about the problems that the developer is struggling with. The code snippets you haveAs a pair programmer, I'm happy to help you. However, I need more information about the problems that the developer is struggling with. The code snippets you have sharedAs a pair programmer, I'm happy to help you. However, I need more information about the problems that the developer is struggling with. The code snippets you have shared doAs a pair programmer, I'm happy to help you. However, I need more information about the problems that the developer is struggling with. The code snippets you have shared do notAs a pair programmer, I'm happy to help you. However, I need more information about the problems that the developer is struggling with. The code snippets you have shared do not provideAs a pair programmer, I'm happy to help you. However, I need more information about the problems that the developer is struggling with. The code snippets you have shared do not provide anyAs a pair programmer, I'm happy to help you. However, I need more information about the problems that the developer is struggling with. The code snippets you have shared do not provide any contextAs a pair programmer, I'm happy to help you. However, I need more information about the problems that the developer is struggling with. The code snippets you have shared do not provide any context.As a pair programmer, I'm happy to help you. However, I need more information about the problems that the developer is struggling with. The code snippets you have shared do not provide any context. CanAs a pair programmer, I'm happy to help you. However, I need more information about the problems that the developer is struggling with. The code snippets you have shared do not provide any context. Can youAs a pair programmer, I'm happy to help you. However, I need more information about the problems that the developer is struggling with. The code snippets you have shared do not provide any context. Can you pleaseAs a pair programmer, I'm happy to help you. However, I need more information about the problems that the developer is struggling with. The code snippets you have shared do not provide any context. Can you please provideAs a pair programmer, I'm happy to help you. However, I need more information about the problems that the developer is struggling with. The code snippets you have shared do not provide any context. Can you please provide moreAs a pair programmer, I'm happy to help you. However, I need more information about the problems that the developer is struggling with. The code snippets you have shared do not provide any context. Can you please provide more informationAs a pair programmer, I'm happy to help you. However, I need more information about the problems that the developer is struggling with. The code snippets you have shared do not provide any context. Can you please provide more information aboutAs a pair programmer, I'm happy to help you. However, I need more information about the problems that the developer is struggling with. The code snippets you have shared do not provide any context. Can you please provide more information about theAs a pair programmer, I'm happy to help you. However, I need more information about the problems that the developer is struggling with. The code snippets you have shared do not provide any context. Can you please provide more information about the issuesAs a pair programmer, I'm happy to help you. However, I need more information about the problems that the developer is struggling with. The code snippets you have shared do not provide any context. Can you please provide more information about the issues theAs a pair programmer, I'm happy to help you. However, I need more information about the problems that the developer is struggling with. The code snippets you have shared do not provide any context. Can you please provide more information about the issues the developerAs a pair programmer, I'm happy to help you. However, I need more information about the problems that the developer is struggling with. The code snippets you have shared do not provide any context. Can you please provide more information about the issues the developer isAs a pair programmer, I'm happy to help you. However, I need more information about the problems that the developer is struggling with. The code snippets you have shared do not provide any context. Can you please provide more information about the issues the developer is experiencingAs a pair programmer, I'm happy to help you. However, I need more information about the problems that the developer is struggling with. The code snippets you have shared do not provide any context. Can you please provide more information about the issues the developer is experiencing andAs a pair programmer, I'm happy to help you. However, I need more information about the problems that the developer is struggling with. The code snippets you have shared do not provide any context. Can you please provide more information about the issues the developer is experiencing and whereAs a pair programmer, I'm happy to help you. However, I need more information about the problems that the developer is struggling with. The code snippets you have shared do not provide any context. Can you please provide more information about the issues the developer is experiencing and where As a pair programmer, I'm happy to help you. However, I need more information about the problems that the developer is struggling with. The code snippets you have shared do not provide any context. Can you please provide more information about the issues the developer is experiencing and where theyAs a pair programmer, I'm happy to help you. However, I need more information about the problems that the developer is struggling with. The code snippets you have shared do not provide any context. Can you please provide more information about the issues the developer is experiencing and where they needAs a pair programmer, I'm happy to help you. However, I need more information about the problems that the developer is struggling with. The code snippets you have shared do not provide any context. Can you please provide more information about the issues the developer is experiencing and where they need assistanceAs a pair programmer, I'm happy to help you. However, I need more information about the problems that the developer is struggling with. The code snippets you have shared do not provide any context. Can you please provide more information about the issues the developer is experiencing and where they need assistance?As a pair programmer, I'm happy to help you. However, I need more information about the problems that the developer is struggling with. The code snippets you have shared do not provide any context. Can you please provide more information about the issues the developer is experiencing and where they need assistance?"
     ]
    }
   ],
   "source": [
    "out = chatgpt(res, audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "treehacks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "54b438c93a04fac52b61aa9b1a1452c85bc92b5b728e333bac973eb890debee5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
